ğŸ§  ANÃLISIS ESTRUCTURADO DEL CÃ“DIGO
ğŸ§© 1. Importaciones
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.model_selection import train_test_split


ğŸ”¹ AquÃ­ se cargan todas las librerÃ­as esenciales:

pandas, numpy: manejo y transformaciÃ³n de datos.

matplotlib, seaborn: visualizaciÃ³n de resultados.

joblib: carga de modelos previamente entrenados.

sklearn.metrics: cÃ¡lculo de mÃ©tricas (RÂ², RMSE, MAE).

train_test_split: separaciÃ³n entre entrenamiento y prueba.

ğŸ“¦ Equivalente modular â†’ esto corresponde al mÃ³dulo data_preprocessor.py y predictor.py del sistema grande.
AquÃ­ no se entrena el modelo, solo se usa uno ya entrenado y guardado.

ğŸ“‚ 2. DefiniciÃ³n de rutas
ruta_csv = "/content/drive/MyDrive/ML Glucosa/Glucosa_Unique_Completo.csv"
ruta_modelo = "/content/drive/MyDrive/ML Glucosa/modelo_gradient_boosting_2.joblib"


ğŸ”¹ Se establecen las rutas absolutas de los archivos:

Un archivo .csv con los datos originales.

Un modelo .joblib que fue previamente entrenado y guardado.

ğŸ“¦ Equivalente modular â†’ parte del mÃ³dulo database_manager.py o data_loader.py.
Su funciÃ³n es cargar las fuentes necesarias para el anÃ¡lisis.

ğŸ§¾ 3. Carga de datos y modelo
df = pd.read_csv(ruta_csv)
model = joblib.load(ruta_modelo)


ğŸ”¹ Se cargan:

El dataset completo en un DataFrame.

El modelo entrenado en memoria.

ğŸ’¡ Este modelo ya tiene pesos y parÃ¡metros definidos, por lo que no se reentrena.
A partir de este punto solo se hacen predicciones y validaciones.

âš•ï¸ 4. CreaciÃ³n de la categorÃ­a de glucosa
def clasificar_glucosa(valor):
    if valor <= 100:
        return "Normal"
    elif valor <= 125:
        return "Prediabetes"
    else:
        return "Diabetes"

df["Categoria_Glucosa"] = df["Resultado"].apply(clasificar_glucosa)


ğŸ”¹ Se crea una variable categÃ³rica derivada de la glucosa (variable objetivo).
Esto ayuda a clasificar los resultados de forma interpretativa.

ğŸ“¦ Equivalente modular â†’ feature_engineering.py
AquÃ­ ocurre una transformaciÃ³n del dataset para aÃ±adir variables derivadas Ãºtiles para anÃ¡lisis posteriores.

ğŸ§® 5. SelecciÃ³n de caracterÃ­sticas
features_seleccionadas = [
    "Edad_AÃ±os", "peso", "talla",
    "imc", "tas", "tad", "Categoria_Glucosa"
]
target = "Resultado"


ğŸ”¹ Se definen las variables predictoras (X) y la variable objetivo (y).
Estas caracterÃ­sticas deben coincidir con las usadas para entrenar el modelo originalmente.

ğŸ“¦ Equivalente modular â†’ data_preprocessor.py.
Se encarga de limpiar, seleccionar y preparar los datos antes de predecir.

âœ‚ï¸ 6. DivisiÃ³n de datos
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)


ğŸ”¹ El dataset se divide en:

70% para entrenamiento (aunque aquÃ­ no se entrena, se usa para verificar consistencia),

30% para prueba (evaluaciÃ³n real del modelo).

ğŸ“¦ Equivalente modular â†’ parte de model_trainer.py, aunque aquÃ­ solo se usa para evaluaciÃ³n del modelo ya guardado.

ğŸ”® 7. Predicciones
y_pred_train = model.predict(X_train)
y_pred_test  = model.predict(X_test)


ğŸ”¹ Se generan predicciones tanto para el conjunto de entrenamiento como de prueba.
Esto permite comparar cÃ³mo el modelo se comporta en ambos escenarios (detectando sobreajuste, por ejemplo).

ğŸ“¦ Equivalente modular â†’ predictor.py

ğŸ“Š 8. CÃ¡lculo de mÃ©tricas
r2_tr = r2_score(y_train, y_pred_train)
rmse_tr = np.sqrt(mean_squared_error(y_train, y_pred_train))
mae_tr = mean_absolute_error(y_train, y_pred_train)

r2_te = r2_score(y_test, y_pred_test)
rmse_te = np.sqrt(mean_squared_error(y_test, y_pred_test))
mae_te = mean_absolute_error(y_test, y_pred_test)


ğŸ”¹ Se evalÃºa la precisiÃ³n del modelo con tres mÃ©tricas estÃ¡ndar:

MÃ©trica	QuÃ© mide
RÂ² (Coeficiente de determinaciÃ³n)	QuÃ© tan bien el modelo explica la variabilidad de los datos.
RMSE (Root Mean Squared Error)	CuÃ¡nto se desvÃ­a, en promedio, la predicciÃ³n del valor real.
MAE (Mean Absolute Error)	Error absoluto promedio.

ğŸ“¦ Equivalente modular â†’ model_evaluator.py

ğŸ§¾ 9. Reporte de resultados
print("="*50)
print("EVALUACIÃ“N DEL MODELO GRADIENT BOOSTING")
...


ğŸ”¹ Se imprime un resumen en consola con las mÃ©tricas clave para entrenamiento y prueba.

Ejemplo de salida:

==================================================
EVALUACIÃ“N DEL MODELO GRADIENT BOOSTING
==================================================
[ENTRENAMIENTO] RÂ²=0.982 | RMSE=3.25 | MAE=2.54 | n=700
[PRUEBA       ] RÂ²=0.912 | RMSE=6.80 | MAE=5.42 | n=300
==================================================


ğŸ“¦ Equivalente modular â†’ model_monitoring.py o integraciÃ³n con MLflow.

ğŸ“ˆ 10. VisualizaciÃ³n de desempeÃ±o
sns.scatterplot(data=df_plot, x="y_true", y="y_pred", hue="split", style="split", alpha=0.7)
plt.plot(xs, xs, '--', color='black', label="PredicciÃ³n Perfecta (y = x)")
...


ğŸ”¹ Se compara visualmente los valores reales vs. predichos.
La lÃ­nea y = x representa una predicciÃ³n perfecta.

ğŸ“Š Si los puntos estÃ¡n cerca de esa lÃ­nea, el modelo es preciso.
La separaciÃ³n indica el grado de error.

ğŸ“¦ Equivalente modular â†’ visualization.py

âš™ï¸ Resumen del flujo
Etapa	DescripciÃ³n	Equivalente modular en sistema completo
Importaciones	LibrerÃ­as base	ConfiguraciÃ³n inicial
Cargar datos/modelo	Lectura de CSV y modelo .joblib	data_loader + database_manager
ClasificaciÃ³n de glucosa	IngenierÃ­a de variables	feature_engineering
SelecciÃ³n de features	PreparaciÃ³n de entrada	data_preprocessor
DivisiÃ³n train/test	SeparaciÃ³n de datos	model_trainer
Predicciones	Uso del modelo guardado	predictor
EvaluaciÃ³n	CÃ¡lculo de mÃ©tricas	model_evaluator
VisualizaciÃ³n	ComparaciÃ³n grÃ¡fica	visualization
Reporte	Resultados interpretables	model_monitoring
ğŸ§© En resumen

Este script representa la etapa final del ciclo de machine learning:
la evaluaciÃ³n y validaciÃ³n de un modelo entrenado.

El modelo ya pasÃ³ por:

Entrenamiento (fuera del script, en otro proceso),

OptimizaciÃ³n y guardado (joblib),

Y ahora se usa para validar su precisiÃ³n en datos nuevos.
